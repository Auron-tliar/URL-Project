{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Random Clusters with Specified Degree of Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from scipy import optimize as opt\n",
    "from scipy.stats import ortho_group\n",
    "import matplotlib as plt\n",
    "import random\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from kemlglearn.cluster.consensus import SimpleConsensusClustering\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main (and only) function to call to generate the dataset of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sepclusters(n_features, n_clusters, n_noisy=0, sep_degree=0.2, sep_quantile=1.96, sep_error = 0.001, outliers=0,\n",
    "                     lambda_min=1, lambda_ratio=10, min_cluster_size=10, max_cluster_size=100):\n",
    "    y=[]\n",
    "    \n",
    "    # Step 2: Generate cluster centers and random cvariance matrices in non-noisy dimensions \n",
    "    # satisfying separation parameter\n",
    "    centers, Covariances = cluster_center_allocation(n_features, n_clusters, sep_degree, sep_quantile, \n",
    "                                                     lambda_min, lambda_ratio, sep_error)\n",
    "    \n",
    "    # Step 3: Generate sizes of each cluster and generate memberships of each datapoint\n",
    "    N_clus = [np.random.randint(min_cluster_size,max_cluster_size + 1) for i in range(n_clusters)]\n",
    "    N = sum(N_clus)\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(N_clus[i]):\n",
    "            y.append(i)\n",
    "    \n",
    "    # Step 4: Generate the mean vector and covariance matrix of the noisy variables\n",
    "    indices = []\n",
    "    if n_noisy > 0:\n",
    "        p = np.array(N_clus) / N\n",
    "        Cov_mix = np.zeros(Covariances[0].shape)\n",
    "        cent_mix = np.zeros(centers[0].shape)\n",
    "        for i in range(len(Covariances)):\n",
    "            Cov_mix += p[i]*Covariances[i]\n",
    "            cent_mix += p[i]*centers[i]\n",
    "\n",
    "        for kp in range(len(Covariances)):\n",
    "            for k in range(kp):\n",
    "                Cov_mix += p[k]*p[kp] * np.matmul((centers[k] - centers[kp]),np.transpose(centers[k] - centers[kp]))\n",
    "\n",
    "        min_cent_mix = min(cent_mix)\n",
    "        max_cent_mix = max(cent_mix)\n",
    "        center_noisy = np.array([np.random.uniform(min_cent_mix,max_cent_mix) for i in range(n_noisy)])\n",
    "        eigenvalues_mix, _ = LA.eig(Cov_mix)\n",
    "        eigenvalues_mix = np.sort(eigenvalues_mix)\n",
    "\n",
    "        Covariance_noisy = generate_covariance(n_noisy, eigenvalues_mix[0], \n",
    "                                               eigenvalues_mix[n_noisy-1]/eigenvalues_mix[0])\n",
    "    perm = np.random.permutation(n_features + n_noisy)\n",
    "            \n",
    "        \n",
    "    # Step 5: Apply a random rotation to the cluster means and covariance matrices in Step 2\n",
    "    rotation = ortho_group.rvs(n_features)\n",
    "    \n",
    "    # Step 7: Generate random vectors for each of the K clusters from a given family of elliptical distributions.\n",
    "    if outliers < 1:\n",
    "        X = np.zeros([N+int(outliers*N),n_features+n_noisy])\n",
    "    else:\n",
    "        X = np.zeros([N+outliers,n_features+n_noisy])\n",
    "    ind = 0\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(N_clus[i]):\n",
    "            x = np.random.multivariate_normal(centers[i][:,0], Covariances[i])\n",
    "            x = np.transpose(np.matmul(rotation, np.transpose(x)))\n",
    "            if n_noisy > 0:\n",
    "                x = np.append(x, np.random.multivariate_normal(center_noisy[:,0], Covariance_noisy))\n",
    "            X[ind,:] = x\n",
    "            ind += 1\n",
    "    \n",
    "    X = X[:,perm]\n",
    "    \n",
    "    # Step 8: Calculate the population separation index matrices and projection directions for pairs of clusters \n",
    "    # via the population mean vectors and covariance matrices.\n",
    "    \n",
    "    J = np.ones([n_clusters,n_clusters])\n",
    "    A = [[np.zeros([n_features+n_noisy,1]) for j in range(n_clusters)] for i in range(n_clusters)]\n",
    "    pop_centers = []\n",
    "    pop_Covariances = []\n",
    "    \n",
    "    next_ind = 0\n",
    "    for i in range(n_clusters):\n",
    "        pop_centers.append(np.transpose(np.mean(X[next_ind:(next_ind+N_clus[i]),:],0)))\n",
    "        pop_Covariances.append(np.cov(np.transpose(X[next_ind:(next_ind+N_clus[i]),:])))\n",
    "        next_ind += N_clus[i]\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        for j in range(i+1,n_clusters):\n",
    "            # Find optimal projection direction\n",
    "            mu1 = pop_centers[i]\n",
    "            mu2 = pop_centers[j]\n",
    "            Sigma1 = pop_Covariances[i]\n",
    "            Sigma2 = pop_Covariances[j]\n",
    "            a = optimal_projection(mu1, mu2, Sigma1, Sigma2, sep_quantile)\n",
    "            A[i][j] = a\n",
    "            A[j][i] = a\n",
    "            J[i,j] = calculate_J(mu1, mu2, Sigma1, Sigma2, sep_quantile, a)\n",
    "            J[j,i] = J[i,j]\n",
    "    \n",
    "    #print(J)\n",
    "    \n",
    "    \n",
    "    # Step 10: Generate outliers. The memberships of outliers are assigned as zero\n",
    "    pop_mean = np.mean(X,0)\n",
    "    pop_std = np.std(X,0)\n",
    "    out_min = pop_mean - 4*pop_std\n",
    "    out_max = pop_mean + 4*pop_std\n",
    "    for i in range(N, X.shape[0]):\n",
    "        X[i,:] = np.random.uniform(out_min, out_max)\n",
    "        y.append(np.nan)\n",
    "        \n",
    "    perm_ex = np.random.permutation(X.shape[0])\n",
    "    \n",
    "    X = X[perm_ex,:]\n",
    "    y = np.array(y)\n",
    "    y = y[perm_ex]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_center_allocation(n_features, n_clusters, sep_degree, sep_quantile, lambda_min, lambda_ratio, sep_error):\n",
    "    \n",
    "    # Step (a): generate K covariance mantrices in n_features dimensions\n",
    "    Covariances = [generate_covariance(n_features, lambda_min, lambda_ratio) for i in range(n_clusters)]\n",
    "    \n",
    "    # Step (b): Construct simplex\n",
    "    edge = 2\n",
    "    V = calculate_vertices(edge, n_features)\n",
    "    \n",
    "    # Step (c): allocate cluster centers\n",
    "    centers = calculate_centers(V, n_clusters)\n",
    "    \n",
    "    # Step (d): Calculate separation matrix\n",
    "    J = np.ones([n_clusters,n_clusters])\n",
    "    A = [[np.zeros([n_features,1]) for j in range(n_clusters)] for i in range(n_clusters)]\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(i+1,n_clusters):\n",
    "            # Find optimal projection direction\n",
    "            mu1 = centers[i]\n",
    "            mu2 = centers[j]\n",
    "            Sigma1 = Covariances[i]\n",
    "            Sigma2 = Covariances[j]\n",
    "            a = optimal_projection(mu1, mu2, Sigma1, Sigma2, sep_quantile)\n",
    "            A[i][j] = a\n",
    "            A[j][i] = a\n",
    "            J[i,j] = calculate_J(mu1, mu2, Sigma1, Sigma2, sep_quantile, a)\n",
    "            J[j,i] = J[i,j]\n",
    "    \n",
    "    # Step (e): Scale the length of simplex edge\n",
    "    min_sep = np.min(J)\n",
    "    min_edge = 0\n",
    "    max_edge = np.inf\n",
    "    while np.abs(min_sep - sep_degree) > sep_error:\n",
    "        if min_sep < sep_degree:\n",
    "            min_edge = edge\n",
    "            if np.isinf(max_edge):\n",
    "                edge *= 2\n",
    "            else:\n",
    "                edge = (edge + max_edge) / 2\n",
    "        elif min_sep > sep_degree:\n",
    "            max_edge = edge\n",
    "            edge = (edge + min_edge) / 2\n",
    "        \n",
    "        V = calculate_vertices(edge, n_features)\n",
    "        centers = calculate_centers(V, n_clusters)\n",
    "        J = calculate_Js(n_clusters, centers, Covariances, sep_quantile, A)\n",
    "        min_sep = np.min(J)\n",
    "    \n",
    "    # Step (f): Compute separation indeces between custers and their nearest neighbors. If conditions are satisfied - stop,\n",
    "    # otherwise - Step (g)\n",
    "    Jk = np.min(J,1)\n",
    "    k_opt = np.argmax(Jk)\n",
    "    \n",
    "    while np.abs(Jk[k_opt] - sep_degree) > sep_error:\n",
    "        # Step (g): Scale the covariance matrix\n",
    "        mu1 = centers[k_opt]\n",
    "        k2_min = np.argmin(J[k_opt,:])\n",
    "        mu2 = centers[k2_min]\n",
    "        Sigma1 = Covariances[k_opt]\n",
    "        Sigma2 = Covariances[k2_min]\n",
    "        a = A[k_opt][k2_min]\n",
    "        \n",
    "        func = (lambda x: (np.matmul(np.transpose(a),(mu2-mu1))-sep_quantile*\n",
    "                         (np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma1*x),a)) + \n",
    "                          np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma2),a)))) /\n",
    "                     (np.matmul(np.transpose(a),(mu2-mu1))+sep_quantile*\n",
    "                         (np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma1*x),a)) + \n",
    "                          np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma2),a)))) - sep_degree)\n",
    "        \n",
    "        func_obj = (lambda x: np.abs((np.matmul(np.transpose(a),(mu2-mu1))-sep_quantile*\n",
    "                         (np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma1*x),a)) + \n",
    "                          np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma2),a)))) /\n",
    "                     (np.matmul(np.transpose(a),(mu2-mu1))+sep_quantile*\n",
    "                         (np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma1*x),a)) + \n",
    "                          np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma2),a)))) - sep_degree))\n",
    "        \n",
    "        \n",
    "        if func(1) > 0:\n",
    "            res = opt.minimize(func_obj, 1.01, constraints=[{'type':'ineq','fun':(lambda x: \n",
    "                               np.matmul(np.matmul(np.transpose(a),Sigma1*x),a))}],\n",
    "                         bounds=[(1.001,None)])\n",
    "        else:\n",
    "            res = opt.minimize(func_obj, 0.99, constraints=[{'type':'ineq','fun':(lambda x: \n",
    "                               np.matmul(np.matmul(np.transpose(a),Sigma1*x),a))}],\n",
    "                         bounds=[(0,0.999)])\n",
    "        Covariances[k_opt] = Covariances[k_opt]*res.x[0]\n",
    "        \n",
    "        J = calculate_Js(n_clusters, centers, Covariances, sep_quantile, A)\n",
    "        Jk = np.min(J,1)\n",
    "        k_opt = np.argmax(Jk)\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        J[i,i] = -1.\n",
    "        \n",
    "    #print(J)\n",
    "    \n",
    "    return centers, Covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_covariance(n_features, lambda_min, lambda_ratio):\n",
    "    lambda_min = np.abs(lambda_min)\n",
    "    lambda_ratio = np.abs(lambda_ratio)\n",
    "        \n",
    "    eigenvalues = np.array([np.random.uniform(lambda_min, lambda_min * lambda_ratio) for i in range(n_features)])\n",
    "    eigenvalues = np.sort(eigenvalues)[::-1]\n",
    "    L = np.diag(eigenvalues)\n",
    "    Q = ortho_group.rvs(n_features)\n",
    "    C = np.matmul(np.matmul(Q, L), np.transpose(Q))\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_mean(V):\n",
    "    v = np.array(V[0])\n",
    "    k = len(V)\n",
    "    for i in range(1,k):\n",
    "        v += V[i]\n",
    "    v /= k\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_vertex(V,edge):\n",
    "    k = len(V)\n",
    "    p = len(V[0])\n",
    "    vk = v_mean(V)\n",
    "    v = np.array(vk)\n",
    "    for i in range(k,p):\n",
    "        v[i] = 0\n",
    "    t = 0\n",
    "    for i in range(0,k):\n",
    "        t += np.matmul(np.transpose(V[i] - vk), (V[i] - vk))\n",
    "    v[k-1] = np.sqrt(edge*edge - t/k)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_projection(mu1, mu2, Sigma1, Sigma2, quantile):\n",
    "    res = opt.minimize(lambda x: -(np.matmul(np.transpose(x),(mu2-mu1))-quantile*\n",
    "                                      (np.sqrt(np.matmul(np.matmul(np.transpose(x),Sigma1),x)) + \n",
    "                                       np.sqrt(np.matmul(np.matmul(np.transpose(x),Sigma2),x)))) /\n",
    "                                  (np.matmul(np.transpose(x),(mu2-mu1))+quantile*\n",
    "                                      (np.sqrt(np.matmul(np.matmul(np.transpose(x),Sigma1),x)) + \n",
    "                                       np.sqrt(np.matmul(np.matmul(np.transpose(x),Sigma2),x)))),\n",
    "                 (mu2 - mu1), constraints={'type':'ineq','fun':(lambda x: np.matmul(np.transpose(x),(mu2-mu1)))})\n",
    "    \n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Js(n_clusters, centers, Covariances, quantile, A):\n",
    "    J = np.ones([n_clusters,n_clusters])\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(i+1,n_clusters):\n",
    "            mu1 = centers[i]\n",
    "            mu2 = centers[j]\n",
    "            Sigma1 = Covariances[i]\n",
    "            Sigma2 = Covariances[j]\n",
    "            a = A[i][j]\n",
    "            J[i,j] = calculate_J(mu1, mu2, Sigma1, Sigma2, quantile, a)\n",
    "            J[j,i] = J[i,j]\n",
    "            \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_J(mu1, mu2, Sigma1, Sigma2, quantile, a):\n",
    "    J = ((np.matmul(np.transpose(a),(mu2-mu1))-quantile * (np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma1),a)) + \n",
    "           np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma2),a)))) /\n",
    "         (np.matmul(np.transpose(a),(mu2-mu1))+quantile * (np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma1),a)) + \n",
    "           np.sqrt(np.matmul(np.matmul(np.transpose(a),Sigma2),a)))))\n",
    "            \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vertices(edge,n_features):\n",
    "    V = []\n",
    "    V.append(-np.eye(n_features,1)*edge/2)\n",
    "    V.append( np.eye(n_features,1)*edge/2)\n",
    "    for i in range(2,n_features + 1):\n",
    "        V.append(next_vertex(V,edge))\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centers(V, n_clusters):\n",
    "    p = len(V[0])\n",
    "    if n_clusters <= p + 1:\n",
    "        centers = V[:n_clusters]\n",
    "    else:\n",
    "        centers = V\n",
    "        p1 = p+1\n",
    "        for i in range(p1, n_clusters):\n",
    "            centers.append(V[1 + i%p1] + np.eye(p,1) * 2 * int(i/p1))\n",
    "    \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test datasets generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for s in [0.01,0.21,0.342]:\n",
    "    for noise in [2,0]:\n",
    "        XX,yy = make_sepclusters(n_features=4, n_clusters=3, sep_degree=s, n_noisy=noise, min_cluster_size=30, \n",
    "                                 max_cluster_size=100, outliers = 20)\n",
    "        X.append(XX)\n",
    "        y.append(yy)\n",
    "    \n",
    "for s in [0.01,0.21,0.342]:\n",
    "    for noise in [2,0]:\n",
    "        XX,yy = make_sepclusters(n_features=4, n_clusters=3, sep_degree=s, n_noisy=noise, min_cluster_size=30, \n",
    "                                 max_cluster_size=100, outliers = 0)\n",
    "        X.append(XX)\n",
    "        y.append(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec31ba3e451e47c68e583bb180345030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='DATA', max=6, min=1), IntSlider(value=3, description='NE…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(DATA = (1,6,1), NEIGHBORS = (3, 15, 2), OUTLIERS = (0.1, 0.4))\n",
    "def g(DATA = 1, NEIGHBORS=3, OUTLIERS=0.1):\n",
    "    lof = LocalOutlierFactor(n_neighbors=NEIGHBORS, contamination=OUTLIERS)    \n",
    "    labels = lof.fit_predict(X[DATA-1])\n",
    "    count_correct = 0\n",
    "    count_outliers = 0.\n",
    "    count_incorrect = 0\n",
    "    for i in range(len(y[DATA-1])):\n",
    "        if np.isnan(y[DATA-1][i]):\n",
    "            count_outliers += 1\n",
    "            if labels[i] == -1:\n",
    "                count_correct += 1\n",
    "        elif labels[i] == -1:\n",
    "            count_incorrect += 1\n",
    "    total = count_correct + count_incorrect\n",
    "    print(\"Correct outliers: \", count_correct/count_outliers, \"(\",count_correct,\"/\",count_outliers,\")\")\n",
    "    print(\"Incorrect outliers: \", count_incorrect/total, \"(\",count_incorrect,\"/\",total,\")\")\n",
    "    fig = plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(X[DATA-1][:, 2], X[DATA-1][:, 1], c=labels,s=100)\n",
    "    plt.title('Outliers/Inliers')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(X[DATA-1][:, 2], X[DATA-1][:, 1], c=lof.negative_outlier_factor_,s=100)\n",
    "    plt.title('LOF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f490c861035c4671ada1b5c7d10ab4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='DATA', max=12, min=1), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(DATA = (1, 12, 1))\n",
    "def g(DATA=1):\n",
    "    km = KMeans(n_clusters=3)\n",
    "    km.fit(X[DATA-1])\n",
    "    labels = km.predict(X[DATA-1])\n",
    "    print(adjusted_mutual_info_score(y[DATA-1], labels))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(X[DATA-1][:, 2], X[DATA-1][:, 1], c=labels, s=100)\n",
    "    plt.scatter(km.cluster_centers_[:,2], km.cluster_centers_[:,1], c='r', s=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d449528c4b34f2dbf5235ae8b2c1876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='DATA', max=12, min=1), IntSlider(value=1, description='e…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(DATA = (1, 12, 1), eps = (1, 11, 2), ms = (5, 50, 5))\n",
    "def g(DATA = 1, eps=1, ms=5):\n",
    "    dbs = DBSCAN(eps=eps, min_samples=ms)\n",
    "    labels = dbs.fit_predict(X[DATA-1])\n",
    "    unq = len(np.unique(labels))\n",
    "    print(\"NClusters\", unq-1)\n",
    "    sc = adjusted_mutual_info_score(y[DATA-1], labels)\n",
    "    print(sc)\n",
    "    ecolors = np.array(labels)\n",
    "    ecolors[ecolors == -1] += unq+25\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(X[DATA-1][:, 0], X[DATA-1][:, 1], c=ecolors/unq+25, s=50);\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de926720504466285f8b9ffdf658233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='DATA', max=12, min=1), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(DATA = (1, 12, 1))\n",
    "def g(DATA = 1):\n",
    "    cons = SimpleConsensusClustering(n_clusters=3, n_clusters_base=10, n_components=30, ncb_rand=False)\n",
    "    cons.fit(X[DATA-1])\n",
    "    labels = cons.labels_\n",
    "    print('SCC AMI =', adjusted_mutual_info_score(labels,y[DATA-1]))\n",
    "    fig = plt.figure(figsize=(20,7))\n",
    "    ax = fig.add_subplot(121)\n",
    "    plt.scatter(X[DATA-1][:,0],X[DATA-1][:,1],c=y[DATA-1])\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.scatter(X[DATA-1][:,0],X[DATA-1][:,1],c=labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
